{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problem2: Face Recognition Using SVM and PCA:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77568c62cb78ffa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### a) Download the dataset “Face” from this link:  https://drive.google.com/drive/folders/14Mi1I91iVQ13PG0SPjh9wN5NSNlBb3rb?usp=sharingLinks to an external site.\n",
    "\n",
    "#### Check out the dataset. This is an image dataset from AT&T research lab. It includes 400 faces (64x64 pixels) from 40 people (10 images per person).\n",
    "\n",
    "#### You have to also download the csv file that includes the labels of the images (the label is person’s ID. The file is in the same folder). The goal is to build a Face Recognition algorithm to recognize each person using PCA dim-reduction and a non-linear SVM.\n",
    "\n",
    "#### you can use:\n",
    "\n",
    "#### mpimg.imread(file_name)   to load an image, and\n",
    "\n",
    "#### plt.imshow(image_name, cmap=plt.cm.gray)  to show an image (This is a little different from what we had before!). Add   %matplotlib inline   at top of your code to make sure that the images will be shown inside the Jupyter explorer page."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f6c50c35c252d72"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "csv_path = 'label.csv'\n",
    "\n",
    "labels = pd.read_csv(csv_path)\n",
    "\n",
    "images = np.empty((400, 4096))\n",
    "\n",
    "files_in_folder = os.listdir('./Face')\n",
    "files_in_folder.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "for i, file in enumerate(files_in_folder):\n",
    "    if file != 'label.csv':\n",
    "        path = os.path.join('./Face/', file)\n",
    "        images[i] = mpimg.imread(path).flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:55:26.992257100Z",
     "start_time": "2024-04-09T04:55:19.490303200Z"
    }
   },
   "id": "b08bbb76cd8fbdee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### b) Build the feature matrix and label vector: Each image is considered as a data sample with pixels as features. Thus, to build the feature table you have to convert each 64x64 image into a row of the feature matrix with 4096 columns (i.e 4096 features for 4096 pixels)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "796a0eeb253fb32f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "prob2_X = images\n",
    "prob2_y = labels['Label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:28.612565500Z",
     "start_time": "2024-04-05T01:10:28.599049300Z"
    }
   },
   "id": "2fe727982d6cd704"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### c) Normalizations: Normalize each column of your feature matrix using preprocessing.scale (This step is very important!)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37cc6be1e05cab20"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.37649641,  1.11885303,  0.79610373, ..., -1.17094622,\n        -1.24726506, -1.21711982],\n       [ 1.68113398,  1.3654141 ,  1.03570156, ...,  0.68710075,\n         1.48558299,  1.58234648],\n       [-0.31593455, -0.59063704, -0.75329558, ...,  1.84210291,\n         1.84204144,  1.13304942],\n       [-0.73904229, -0.40982559, -0.49772456, ...,  1.10557979,\n        -0.31368343, -0.99247129],\n       [-0.09591852,  0.31342021,  0.57247909, ...,  0.40253499,\n         0.26343976,  0.71831368]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# normalize/scale the data\n",
    "prob_2_X_norm = preprocessing.scale(prob2_X)\n",
    "prob_2_X_norm[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:28.662687100Z",
     "start_time": "2024-04-05T01:10:28.615593100Z"
    }
   },
   "id": "5bc7fce47bfb4f87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### d) Use sklearn functions to split the normalized dataset into testing and training sets with the following parameters: test_size=0.25, random_state=5."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c80c947ae6f3e49"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(prob_2_X_norm, prob2_y, test_size=0.25, random_state=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:28.675238500Z",
     "start_time": "2024-04-05T01:10:28.662687100Z"
    }
   },
   "id": "fd83219a7eb9c041"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### e) The dimensionality of the data samples is 4096. Use PCA (Principal Component Analysis) to reduce the dimensionality from 4096 to 50 (i.e. only k=50 principal components!). You should “fit” your PCA on your training set only, and then use this fitted model to “transform” both training and testing sets (When you finish this step, the number of columns in your testing and training sets should be 50)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c63efd4819faf5e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from  sklearn.decomposition  import  PCA\n",
    "\n",
    "k = 50  #  k  is the number of components (new features) after dimensionality reduction\n",
    "my_pca = PCA(n_components = k)\n",
    "\n",
    "# new datasets after PCA\n",
    "X_Train_PCA = my_pca.fit_transform(X_train)\n",
    "X_Test_PCA = my_pca.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:28.909896100Z",
     "start_time": "2024-04-05T01:10:28.678245600Z"
    }
   },
   "id": "548211141ab1738f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### f) Design and Train a non-linear SVM classifier with “RBF Kernel” to recognize the face based on the training dataset that you built. Use SVC(C=1, kernel='rbf', gamma=0.0005, random_state=1). Then, Test your SVM on testing set, and calculate and report the accuracy. Also, calculate and report the Confusion Matrix using confusion_matrix(y_test, y_predict)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fbeeec0ef4c729c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=1, kernel='rbf', gamma=0.0005, random_state=1)\n",
    "\n",
    "svm.fit(X_Train_PCA, y_train)\n",
    "\n",
    "y_predict = svm.predict(X_Test_PCA)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:28.942976Z",
     "start_time": "2024-04-05T01:10:28.909896100Z"
    }
   },
   "id": "728ec37330cc7474"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test, y_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:28.958205200Z",
     "start_time": "2024-04-05T01:10:28.943975200Z"
    }
   },
   "id": "c22d848833a2f0d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Accuracy: 91%"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ba44c917c83b519"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 4 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:29.038959100Z",
     "start_time": "2024-04-05T01:10:28.958205200Z"
    }
   },
   "id": "ead7eb991243a097"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix:\n",
    "[[3 0 0 ... 0 0 0]\n",
    " [0 3 0 ... 0 0 0]\n",
    " [0 0 1 ... 0 0 0]\n",
    " ...\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 4 0]\n",
    " [0 0 0 ... 0 0 1]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "591712b399c8415c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### g) Now, use GridSearchCV to find the best value for parameter C in your SVM with scoring='accuracy'. Search in this list: [0.1, 1, 10, 100, 1e3, 5e3, 1e4, 5e4, 1e5] .\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1981aa61a2adbba"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9649999999999999\n",
      "Best C value: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_normalized_pca = my_pca.fit_transform(prob_2_X_norm)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000]}\n",
    "\n",
    "# Create a GridSearchCV object with SVC classifier\n",
    "grid = GridSearchCV(SVC(kernel='rbf', gamma=0.0005, random_state=1), param_grid, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV on the entire dataset after PCA\n",
    "grid_result = grid.fit(X_normalized_pca, prob2_y)\n",
    "\n",
    "# Get the best parameter value\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "print(\"Best C value:\", grid.best_params_['C'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:10:31.418830500Z",
     "start_time": "2024-04-05T01:10:28.975760900Z"
    }
   },
   "id": "c8283831e9b130bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best score: 0.9649999999999999\n",
    "Best C value: 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fa64b243a33c2c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
